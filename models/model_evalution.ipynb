{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96aVsE_vPokU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = Path(\"/content/drive/MyDrive/final_dataset.csv\")\n",
        "df = pd.read_csv(DATA_PATH)"
      ],
      "metadata": {
        "id": "dHHijhhASiEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_col = \"YearMonth\"\n",
        "target_col=\"Recreation Visits\""
      ],
      "metadata": {
        "id": "YS3JQekdSnGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Time column:\", time_col)\n",
        "print(\"Chosen target column for forecasting:\", target_col)"
      ],
      "metadata": {
        "id": "48-F3UPpSqh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_yearmonth(s):\n",
        "    s = str(s).strip()\n",
        "    s = s.replace('/', '-')\n",
        "    # handle YYYYMM like 202305\n",
        "    if len(s) == 6 and s.isdigit():\n",
        "        s = s[:4] + \"-\" + s[4:]\n",
        "    try:\n",
        "        return pd.to_datetime(s, format=\"%Y-%m\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.to_datetime(s)\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "df[time_col] = df[time_col].apply(parse_yearmonth)\n",
        "missing_dates = df[time_col].isna().sum()\n",
        "if missing_dates > 0:\n",
        "    print(f\"Warning: {missing_dates} rows could not be parsed into dates and will be dropped.\")"
      ],
      "metadata": {
        "id": "6s5MWFjJS-0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna(subset=[time_col, target_col]).copy()\n",
        "monthly = df_clean.groupby(pd.Grouper(key=time_col, freq=\"MS\"))[target_col].sum().sort_index().to_frame()\n",
        "monthly = monthly.asfreq(\"MS\")  # ensure continuous monthly index\n",
        "monthly[target_col] = monthly[target_col].fillna(0)"
      ],
      "metadata": {
        "id": "H0Gl1GV-TGoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(monthly.index, monthly[target_col])\n",
        "plt.title(f\"Monthly {target_col}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(target_col)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F0kuzIINTLI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(monthly) >= 36:\n",
        "    test_periods = 12\n",
        "else:\n",
        "    test_periods = max(1, int(len(monthly) * 0.2))\n",
        "\n",
        "train = monthly.iloc[:-test_periods].copy()\n",
        "test = monthly.iloc[-test_periods:].copy()\n",
        "print(f\"Train length: {len(train)}, Test length: {len(test)} (test_periods={test_periods})\")\n"
      ],
      "metadata": {
        "id": "tt-DlnHqTN93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation helper (compatibility-safe: compute RMSE using sqrt) ---\n",
        "def evaluate(true, pred):\n",
        "    # Ensure alignment by index (convert to arrays)\n",
        "    true_arr = np.array(true).astype(float)\n",
        "    pred_arr = np.array(pred).astype(float)\n",
        "    mae = mean_absolute_error(true_arr, pred_arr)\n",
        "    rmse = float(np.sqrt(mean_squared_error(true_arr, pred_arr)))\n",
        "    return {\"MAE\": mae, \"RMSE\": rmse}"
      ],
      "metadata": {
        "id": "RHy8dvL0TPRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "models_tried = []\n",
        "\n",
        "# Baseline: Naive forecast (last observed value from train)\n",
        "try:\n",
        "    last_val = float(train[target_col].iloc[-1])\n",
        "    naive_forecast = pd.Series([last_val] * len(test), index=test.index)\n",
        "    results[\"Naive\"] = evaluate(test[target_col], naive_forecast)\n",
        "    models_tried.append(\"Naive\")\n",
        "except Exception as e:\n",
        "    print(\"Naive baseline failed:\", e)\n",
        "\n",
        "# ETS (Exponential Smoothing)\n",
        "try:\n",
        "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "    ets_model = ExponentialSmoothing(train[target_col], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit(optimized=True)\n",
        "    ets_forecast = ets_model.forecast(steps=len(test))\n",
        "    # ensure same index length/alignment\n",
        "    ets_forecast = pd.Series(ets_forecast, index=test.index)\n",
        "    results[\"ETS\"] = evaluate(test[target_col], ets_forecast)\n",
        "    models_tried.append(\"ETS\")\n",
        "except Exception as e:\n",
        "    print(\"ETS unavailable or failed:\", e)\n",
        "\n",
        "# SARIMAX (basic seasonal ARIMA)\n",
        "try:\n",
        "    import statsmodels.api as sm\n",
        "    sarimax_model = sm.tsa.SARIMAX(train[target_col], order=(1,1,1), seasonal_order=(1,1,1,12),\n",
        "                                   enforce_stationarity=False, enforce_invertibility=False)\n",
        "    sarimax_res = sarimax_model.fit(disp=False)\n",
        "    sarimax_forecast = sarimax_res.forecast(steps=len(test))\n",
        "    sarimax_forecast = pd.Series(sarimax_forecast, index=test.index)\n",
        "    results[\"SARIMAX(1,1,1)(1,1,1,12)\"] = evaluate(test[target_col], sarimax_forecast)\n",
        "    models_tried.append(\"SARIMAX(1,1,1)(1,1,1,12)\")\n",
        "except Exception as e:\n",
        "    print(\"SARIMAX unavailable or failed:\", e)\n",
        "\n",
        "# RandomForest on lag features (safe index intersection)\n",
        "try:\n",
        "    def make_lag_features(series, lags=[1,2,3,6,12], rolling_windows=[3,6]):\n",
        "        df_l = pd.DataFrame({\"y\": series})\n",
        "        for lag in lags:\n",
        "            df_l[f\"lag_{lag}\"] = df_l[\"y\"].shift(lag)\n",
        "        for rw in rolling_windows:\n",
        "            df_l[f\"roll_mean_{rw}\"] = df_l[\"y\"].shift(1).rolling(window=rw, min_periods=1).mean()\n",
        "        df_l = df_l.dropna()\n",
        "        return df_l\n",
        "\n",
        "    df_lags = make_lag_features(monthly[target_col], lags=[1,2,3,6,12], rolling_windows=[3,6])\n",
        "    df_lags_train = df_lags.loc[df_lags.index.intersection(train.index)]\n",
        "    df_lags_test = df_lags.loc[df_lags.index.intersection(test.index)]\n",
        "\n",
        "    if len(df_lags_train) > 0 and len(df_lags_test) > 0:\n",
        "        X_train = df_lags_train.drop(columns=[\"y\"])\n",
        "        y_train = df_lags_train[\"y\"]\n",
        "        X_test = df_lags_test.drop(columns=[\"y\"])\n",
        "        y_test = df_lags_test[\"y\"]\n",
        "        rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "        rf_pred = pd.Series(rf.predict(X_test), index=X_test.index)\n",
        "        results[\"RandomForest_lags\"] = evaluate(y_test, rf_pred)\n",
        "        models_tried.append(\"RandomForest_lags\")\n",
        "    else:\n",
        "        print(\"Not enough data for lag-feature RandomForest (after shifting/index alignment). Skipping RF.\")\n",
        "except Exception as e:\n",
        "    print(\"RandomForest approach failed:\", e)\n",
        "\n",
        "# --- Compile and show evaluation results (safe even if empty) ---\n",
        "if len(results) == 0:\n",
        "    print(\"\\nNo models completed successfully. Check earlier error messages.\\n\")\n",
        "    results_df = pd.DataFrame(columns=[\"Model\", \"MAE\", \"RMSE\"])\n",
        "else:\n",
        "    results_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\":\"Model\"})\n",
        "    # keep numeric columns float\n",
        "    results_df[\"MAE\"] = results_df[\"MAE\"].astype(float)\n",
        "    results_df[\"RMSE\"] = results_df[\"RMSE\"].astype(float)\n",
        "    results_df = results_df.sort_values(\"MAE\").reset_index(drop=True)\n",
        "\n",
        "# Print results (works in plain python shells)\n",
        "print(\"\\nModel evaluation results (lower MAE better):\\n\")\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"\\nModels attempted:\", models_tried)"
      ],
      "metadata": {
        "id": "Hm6aCZI2T-Or"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}