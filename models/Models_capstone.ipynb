{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y prophet fbprophet pystan cmdstanpy"
      ],
      "metadata": {
        "id": "RFYUeYd7zPqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"numpy<2.0\" prophet==1.1.5 cmdstanpy==1.1.0"
      ],
      "metadata": {
        "id": "gLhKsLhdnc3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import prophet, cmdstanpy\n",
        "print(\"Prophet version:\", prophet.__version__)\n",
        "print(\"CmdStanPy version:\", cmdstanpy.__version__)\n",
        "print(\"CmdStan path:\", cmdstanpy.cmdstan_path())\n",
        "from prophet import Prophet\n",
        "m = Prophet()\n",
        "print(\"Backend attached:\", hasattr(m, \"stan_backend\"))"
      ],
      "metadata": {
        "id": "Lgq5fHQcnE1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX"
      ],
      "metadata": {
        "id": "BSqQL6B6y6Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings, signal, time, logging\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "FC91SKetz_dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Capstone project/final_dataset.csv\")\n",
        "df['YearMonth'] = pd.to_datetime(df['YearMonth'])\n",
        "df = df.sort_values(['Park','YearMonth'])"
      ],
      "metadata": {
        "id": "w2edwZdnzLYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jvTTmV9kq4HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(actual, predicted):\n",
        "    actual = np.array(actual)\n",
        "    predicted = np.array(predicted)\n",
        "\n",
        "    # Replace zeros to avoid division errors\n",
        "    actual = np.where(actual == 0, 1e-8, actual)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
        "    smape = 100 * np.mean(np.abs(predicted - actual) / ((np.abs(predicted) + np.abs(actual)) / 2))\n",
        "    r2 = r2_score(actual, predicted)\n",
        "\n",
        "    # Replace invalids with 0\n",
        "    metrics = {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'SMAPE': smape, 'R2': r2}\n",
        "    for k, v in metrics.items():\n",
        "        if np.isnan(v) or np.isinf(v):\n",
        "            metrics[k] = 0\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "rTyqpkTszV9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(filename=\"forecast_errors.log\", level=logging.WARNING,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "class TimeoutException(Exception): pass\n",
        "\n",
        "\n",
        "def handler(signum, frame): raise TimeoutException()\n",
        "signal.signal(signal.SIGALRM, handler)"
      ],
      "metadata": {
        "id": "ctXR8POtzgh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKFbaiLVy2se"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for park,group in df.groupby('Park'):\n",
        "    group = group.sort_values('YearMonth').reset_index(drop=True)\n",
        "    if len(group) < 36:\n",
        "        continue\n",
        "\n",
        "    train = group.iloc[:-12]\n",
        "    test = group.iloc[-12:]\n",
        "    metrics_all = []\n",
        "\n",
        "\n",
        "    # -------- ETS --------\n",
        "    try:\n",
        "        signal.alarm(15)\n",
        "        start = time.time()\n",
        "        ets_model = ExponentialSmoothing(train['Recreation Visits'],\n",
        "                                         trend='add', seasonal='add',seasonal_periods=12).fit()\n",
        "        ets_forecast = ets_model.forecast(len(test))\n",
        "        signal.alarm(0)\n",
        "        ets_metrics = calculate_metrics(test['Recreation Visits'], ets_forecast)\n",
        "        ets_metrics['Model'] = 'ETS'\n",
        "        metrics_all.append(ets_metrics)\n",
        "        print(f\"[ETS OK] {park} ({round(time.time()-start,2)}s)\")\n",
        "    except Exception as e:\n",
        "        signal.alarm(0)\n",
        "        logging.warning(f\"{park}: ETS failed - {e}\")\n",
        "\n",
        "    #-------- SARIMA --------\n",
        "    try:\n",
        "        signal.alarm(20)\n",
        "        start = time.time()\n",
        "        sarima_model = SARIMAX(train['Recreation Visits'],\n",
        "                               order=(1,1,1), seasonal_order=(1,1,1,12)).fit(disp=False)\n",
        "        sarima_forecast = sarima_model.forecast(len(test))\n",
        "        signal.alarm(0)\n",
        "        sarima_metrics = calculate_metrics(test['Recreation Visits'], sarima_forecast)\n",
        "        sarima_metrics['Model'] = 'SARIMA'\n",
        "        metrics_all.append(sarima_metrics)\n",
        "        print(f\"[SARIMA OK] {park} ({round(time.time()-start,2)}s)\")\n",
        "    except Exception as e:\n",
        "        signal.alarm(0)\n",
        "        logging.warning(f\"{park}: SARIMA failed - {e}\")\n",
        "\n",
        "    # -------- PROPHET --------\n",
        "    try:\n",
        "        signal.alarm(20)\n",
        "        start = time.time()\n",
        "        prophet_df = train.rename(columns={'YearMonth': 'ds', 'Recreation Visits': 'y'})\n",
        "        prophet_model = Prophet(yearly_seasonality=True)\n",
        "        prophet_model.fit(prophet_df)\n",
        "        future = prophet_model.make_future_dataframe(periods=len(test), freq='MS')\n",
        "        forecast = prophet_model.predict(future)\n",
        "        prophet_forecast = forecast['yhat'][-len(test):].values\n",
        "        signal.alarm(0)\n",
        "        prophet_metrics = calculate_metrics(test['Recreation Visits'], prophet_forecast)\n",
        "        prophet_metrics['Model'] = 'Prophet'\n",
        "        metrics_all.append(prophet_metrics)\n",
        "        print(f\"[Prophet OK] {park} ({round(time.time()-start,2)}s)\")\n",
        "    except Exception as e:\n",
        "        signal.alarm(0)\n",
        "        logging.warning(f\"{park}: Prophet failed - {e}\")\n",
        "\n",
        "    # to skip if it fails\n",
        "    if not metrics_all:\n",
        "        logging.warning(f\"{park}: All models failed or timed out\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_all)\n",
        "    metrics_df = metrics_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    for col in ['RMSE', 'MAE', 'MAPE', 'SMAPE', 'R2']:\n",
        "        if col not in metrics_df.columns:\n",
        "            metrics_df[col] = 0\n",
        "\n",
        "    metrics_df['MAPE'] = metrics_df['MAPE'].clip(0, 1000)\n",
        "    metrics_df['SMAPE'] = metrics_df['SMAPE'].clip(0, 1000)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    for col in ['RMSE', 'MAE', 'MAPE', 'SMAPE']:\n",
        "        if metrics_df[col].nunique() <= 1:\n",
        "            metrics_df[col + '_norm'] = 0\n",
        "        else:\n",
        "            metrics_df[col + '_norm'] = scaler.fit_transform(metrics_df[[col]])\n",
        "\n",
        "    metrics_df['Composite_Score'] = (\n",
        "        0.25 * metrics_df.get('RMSE_norm', 0) +\n",
        "        0.25 * metrics_df.get('MAE_norm', 0) +\n",
        "        0.25 * metrics_df.get('MAPE_norm', 0) +\n",
        "        0.25 * (1 - metrics_df.get('R2', 0))\n",
        "    )\n",
        "\n",
        "    best_row = metrics_df.sort_values('Composite_Score').iloc[0]\n",
        "    best_model_name = best_row['Model']\n",
        "\n",
        "\n",
        "    try:\n",
        "        full_series = group['Recreation Visits']\n",
        "        last_date = group['YearMonth'].max()\n",
        "\n",
        "        if best_model_name == 'ETS':\n",
        "            final_model = ExponentialSmoothing(full_series,\n",
        "                                               trend='add', seasonal='add', seasonal_periods=12).fit()\n",
        "            future_fc = final_model.forecast(12)\n",
        "            forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1),\n",
        "                                           periods=12, freq='MS')\n",
        "            monthly_forecast = pd.DataFrame({\n",
        "             'Park': park,\n",
        "             'Best_Model': best_model_name,\n",
        "             'Forecast_Month': forecast_dates,\n",
        "             'Predicted_Visits': future_fc.values\n",
        "             })\n",
        "            monthly_forecast['State'] = group['State'].iloc[0]\n",
        "            monthly_forecast['Region'] = group['Region'].iloc[0]\n",
        "\n",
        "        elif best_model_name == 'SARIMA':\n",
        "            final_model = SARIMAX(full_series,order=(1,1,1),seasonal_order=(1,1,1,12)).fit(disp=False)\n",
        "            future_fc = final_model.forecast(12)\n",
        "            forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1),periods=12,freq='MS')\n",
        "            monthly_forecast = pd.DataFrame({\n",
        "                'Park': park,\n",
        "                'Best_Model': best_model_name,\n",
        "                'Forecast_Month': forecast_dates,\n",
        "                'Predicted_Visits': future_fc.values\n",
        "            })\n",
        "            monthly_forecast['State'] = group['State'].iloc[0]\n",
        "            monthly_forecast['Region'] = group['Region'].iloc[0]\n",
        "\n",
        "        else:  # Prophet\n",
        "            prophet_df_full = group.rename(columns={'YearMonth':'ds','Recreation Visits':'y'})\n",
        "            final_model = Prophet(yearly_seasonality=True)\n",
        "            final_model.fit(prophet_df_full)\n",
        "            future = final_model.make_future_dataframe(periods=12,freq='MS')\n",
        "            fc = final_model.predict(future)\n",
        "            forecast_part = fc[['ds', 'yhat']].tail(12)\n",
        "            monthly_forecast = pd.DataFrame({\n",
        "                'Park': park,\n",
        "                'Best_Model': best_model_name,\n",
        "                'Forecast_Month': forecast_part['ds'],\n",
        "                'Predicted_Visits': forecast_part['yhat']\n",
        "            })\n",
        "            monthly_forecast['State'] = group['State'].iloc[0]\n",
        "            monthly_forecast['Region'] = group['Region'].iloc[0]\n",
        "        results.append(monthly_forecast)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"{park}: Final forecast failed - {e}\")\n",
        "        continue\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# STEP 6: COMBINE AND EXPORT MONTHLY FORECASTS\n",
        "# --------------------------------------------\n",
        "final_forecasts = pd.concat(results, ignore_index=True)\n",
        "final_forecasts['Forecast_Month'] = pd.to_datetime(final_forecasts['Forecast_Month'])\n",
        "pd.set_option('display.float_format', '{:,.0f}'.format)\n",
        "# Fix: Replace negative predictions with 0 and round to nearest integer\n",
        "final_forecasts['Predicted_Visits'] = (final_forecasts['Predicted_Visits'].clip(lower=0)\n",
        "              .round().astype(int))\n",
        "\n",
        "final_forecasts.to_csv(\"/content/drive/MyDrive/Capstone project/monthly_forecasts.csv\", index=False)\n",
        "print(\"Monthly forecasts completed and saved to 'monthly_forecasts.csv'\")\n",
        "display(final_forecasts.tail(15))"
      ],
      "metadata": {
        "id": "R6UffYlHolMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}